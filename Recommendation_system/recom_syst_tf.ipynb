{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation Systems using TensorFlow\n",
    "Builds a recommendation engine using Movie Lens data\n",
    "We use the 1M data set for building our recommendation engine. The 1M data contain 1,000,209 anonymous ratings\n",
    "\n",
    "Ratings for approximately 3,900 movies\n",
    "Ratings provided by 6,040 MovieLens users who joined MovieLens in 2000\n",
    "\n",
    "inspired by https://www.youtube.com/watch?v=TNiWwaMGYzo and https://github.com/karthikmswamy/RecSys/blob/master/Train_RecSys.ipynb\n",
    "\n",
    "https://github.com/songgc/TF-recomm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki: https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)\n",
    "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.[1] This family of methods became widely known during the Netflix prize challenge due to its effectiveness as reported by Simon Funk in his 2006 blog post,[2] where he shared his findings with the research community.\n",
    "The original algorithm proposed by Simon Funk in his blog post [2] factorized the user-item rating matrix as the product of two lower dimensional matrices, the first one has a row for each user, while the second has a column for each item. The row or column associated to a specific user or item is referred to as latent factors.[3] Note that, despite its name, in FunkSVD no singular value decomposition is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig_1.PNG' style=\"width:1000px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gj310e\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ratings are contained in the file \"ratings.dat\" and are in the\n",
    "following format:\n",
    "\n",
    "UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gj310e\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "columns = ['UserIDs','MovieIDs','Ratings','Timestamp']\n",
    "data = pd.read_csv('ml-1m\\\\ratings.dat', sep='::', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserIDs</th>\n",
       "      <th>MovieIDs</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserIDs  MovieIDs  Ratings  Timestamp\n",
       "0        1      1193        5  978300760\n",
       "1        1       661        3  978302109\n",
       "2        1       914        3  978301968\n",
       "3        1      3408        4  978300275\n",
       "4        1      2355        5  978824291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "print(set(data['Ratings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test ans train set\n",
    "rows = len(data)\n",
    "data = data.iloc[np.random.permutation(rows)].reset_index(drop=True)\n",
    "split_index = int(rows*0.9)\n",
    "data_train = data[:split_index]\n",
    "data_test = data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x):\n",
    "    return np.clip(x, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is predicted by formula:\n",
    "\n",
    "y_pred[u, i] = global__bias + bias_user[u] + bias_item_[i] + <embedding_user[u], embedding_item[i]>\n",
    "\n",
    "Minimize by:\n",
    "\n",
    "sum_{u, i} |y_pred[u, i] - y_true[u, i]|^2 + lambda(embedding_user[u]|^2 + embedding_item[i]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model for \n",
    "def model(user_batch, movie_batch, user_num, movie_num, dim=5):\n",
    "    bias_global = tf.get_variable('bias_global', shape=[])\n",
    "    w_bias_movie = tf.get_variable('embeddings_bias_movie', shape=[movie_num])\n",
    "    w_bias_user = tf.get_variable('embeddings_bias_user',shape=[user_num])\n",
    "    \n",
    "    bias_user = tf.nn.embedding_lookup(w_bias_user, user_batch, name='bias_user_values')\n",
    "    bias_movie = tf.nn.embedding_lookup(w_bias_movie, movie_batch, name='bias_movie_values')\n",
    "    \n",
    "    w_emb_user = tf.get_variable('embedded_w_user', shape=[user_num, dim],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    w_emb_movie = tf.get_variable('embedded_w_movie', shape=[movie_num, dim],\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    embed_user = tf.nn.embedding_lookup(w_emb_user, user_batch, name='w_user_val')\n",
    "    embed_movie = tf.nn.embedding_lookup(w_emb_movie, movie_batch, name='w_movie_val')\n",
    "    # tf.multiply(X, Y) does element-wise multiplication (not matrix)\n",
    "    infer = tf.reduce_sum(tf.multiply(embed_user, embed_movie), 1) # avarege for columns, so num of rows will be same\n",
    "    infer = tf.add(infer, bias_global)\n",
    "    infer = tf.add(infer, bias_user)\n",
    "    infer = tf.add(infer, bias_movie)\n",
    "    # Computes half the L2 norm of a tensor without the sqrt\n",
    "    regularizer = tf.add(tf.nn.l2_loss(embed_user), tf.nn.l2_loss(embed_movie))\n",
    "    return infer, regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(infer, regularizer, rate_batch, learning_rate=0.1, reg=0.1):\n",
    "    cost = tf.nn.l2_loss(tf.subtract(infer, rate_batch))\n",
    "    penalty = tf.constant(reg, dtype=tf.float32, shape=[], name='l2')\n",
    "    cost_l2 = tf.add(cost, tf.multiply(penalty,regularizer))\n",
    "    train_op = tf.train.FtrlOptimizer(learning_rate).minimize(cost)\n",
    "    return cost_l2, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(df, batch_size):\n",
    "    n_batches = len(df)//batch_size\n",
    "    df = df[:n_batches*batch_size]\n",
    "    x = np.array(df.UserIDs) - 1    # -1 since Users are counted from 1, but embeddings is counted from 0(zero)\n",
    "    y = np.array(df.MovieIDs) - 1   # same as above\n",
    "    z = np.array(df.Ratings)\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        yield x[i:i+batch_size], y[i:i+batch_size], z[i:i+batch_size]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# create the graph object\n",
    "graph = tf.Graph()\n",
    "\n",
    "# list of constants and parameters\n",
    "batch_size = 1000\n",
    "movie_num = data.MovieIDs.max()\n",
    "user_num = data.UserIDs.max()\n",
    "n_epochs = 50\n",
    "\n",
    "with graph.as_default():\n",
    "    user_batch = tf.placeholder(tf.int32, shape=[None], name='user_batches')\n",
    "    movie_batch = tf.placeholder(tf.int32, shape = [None], name='movie_batches')\n",
    "    rate_batch = tf.placeholder(tf.float32, shape = [None], name='rate_batches')\n",
    "    \n",
    "    infer, regularizer = model(user_batch, movie_batch, user_num, movie_num, dim=5)\n",
    "    cost_l2, train_op = loss(infer, regularizer, rate_batch, learning_rate=0.1, reg=0.1)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iteration 500  Train Error 1.124122 time 0.001003 secs\n",
      "epoch 1 iteration 1000  Train Error 0.967979 time 0.001004 secs\n",
      "------ Test Error 0.805490\n",
      "epoch 1 iteration 1500  Train Error 0.794202 time 0.001003 secs\n",
      "epoch 2 iteration 2000  Train Error 0.768316 time 0.001003 secs\n",
      "------ Test Error 0.782309\n",
      "epoch 2 iteration 2500  Train Error 0.752510 time 0.001004 secs\n",
      "epoch 3 iteration 3000  Train Error 0.740782 time 0.001003 secs\n",
      "------ Test Error 0.772454\n",
      "epoch 3 iteration 3500  Train Error 0.731430 time 0.001003 secs\n",
      "epoch 4 iteration 4000  Train Error 0.723497 time 0.001003 secs\n",
      "------ Test Error 0.765911\n",
      "epoch 4 iteration 4500  Train Error 0.717399 time 0.001003 secs\n",
      "epoch 5 iteration 5000  Train Error 0.711839 time 0.001004 secs\n",
      "------ Test Error 0.761136\n",
      "epoch 6 iteration 5500  Train Error 0.706077 time 0.001003 secs\n",
      "epoch 6 iteration 6000  Train Error 0.701160 time 0.001003 secs\n",
      "------ Test Error 0.757733\n",
      "epoch 7 iteration 6500  Train Error 0.697400 time 0.001003 secs\n",
      "epoch 7 iteration 7000  Train Error 0.692856 time 0.001002 secs\n",
      "------ Test Error 0.755286\n",
      "epoch 8 iteration 7500  Train Error 0.689395 time 0.001013 secs\n",
      "epoch 8 iteration 8000  Train Error 0.686089 time 0.001003 secs\n",
      "------ Test Error 0.753551\n",
      "epoch 9 iteration 8500  Train Error 0.683419 time 0.001004 secs\n",
      "epoch 9 iteration 9000  Train Error 0.681231 time 0.001003 secs\n",
      "------ Test Error 0.751903\n",
      "epoch 10 iteration 9500  Train Error 0.679463 time 0.001003 secs\n",
      "epoch 11 iteration 10000  Train Error 0.676656 time 0.001003 secs\n",
      "------ Test Error 0.750573\n",
      "epoch 11 iteration 10500  Train Error 0.674390 time 0.000000 secs\n",
      "epoch 12 iteration 11000  Train Error 0.673178 time 0.001008 secs\n",
      "------ Test Error 0.749270\n",
      "epoch 12 iteration 11500  Train Error 0.670697 time 0.000000 secs\n",
      "epoch 13 iteration 12000  Train Error 0.669300 time 0.001009 secs\n",
      "------ Test Error 0.748682\n",
      "epoch 13 iteration 12500  Train Error 0.667619 time 0.001003 secs\n",
      "epoch 14 iteration 13000  Train Error 0.666562 time 0.000993 secs\n",
      "------ Test Error 0.747819\n",
      "epoch 14 iteration 13500  Train Error 0.665683 time 0.000000 secs\n",
      "epoch 15 iteration 14000  Train Error 0.665180 time 0.001001 secs\n",
      "------ Test Error 0.747082\n",
      "epoch 16 iteration 14500  Train Error 0.663471 time 0.000996 secs\n",
      "epoch 16 iteration 15000  Train Error 0.662045 time 0.001003 secs\n",
      "------ Test Error 0.746624\n",
      "epoch 17 iteration 15500  Train Error 0.661786 time 0.000000 secs\n",
      "epoch 17 iteration 16000  Train Error 0.660041 time 0.000000 secs\n",
      "------ Test Error 0.746296\n",
      "epoch 18 iteration 16500  Train Error 0.659411 time 0.001003 secs\n",
      "epoch 18 iteration 17000  Train Error 0.658340 time 0.001003 secs\n",
      "------ Test Error 0.746118\n",
      "epoch 19 iteration 17500  Train Error 0.657859 time 0.001003 secs\n",
      "epoch 19 iteration 18000  Train Error 0.657496 time 0.001004 secs\n",
      "------ Test Error 0.745778\n",
      "epoch 20 iteration 18500  Train Error 0.657499 time 0.001002 secs\n",
      "epoch 21 iteration 19000  Train Error 0.656259 time 0.001002 secs\n",
      "------ Test Error 0.745482\n",
      "epoch 21 iteration 19500  Train Error 0.655142 time 0.001002 secs\n",
      "epoch 22 iteration 20000  Train Error 0.655311 time 0.001002 secs\n",
      "------ Test Error 0.745151\n",
      "epoch 22 iteration 20500  Train Error 0.653892 time 0.001003 secs\n",
      "epoch 23 iteration 21000  Train Error 0.653604 time 0.001002 secs\n",
      "------ Test Error 0.745236\n",
      "epoch 23 iteration 21500  Train Error 0.652820 time 0.000000 secs\n",
      "epoch 24 iteration 22000  Train Error 0.652592 time 0.001002 secs\n",
      "------ Test Error 0.745059\n",
      "epoch 24 iteration 22500  Train Error 0.652469 time 0.001003 secs\n",
      "epoch 25 iteration 23000  Train Error 0.652722 time 0.001003 secs\n",
      "------ Test Error 0.744901\n",
      "epoch 26 iteration 23500  Train Error 0.651729 time 0.001002 secs\n",
      "epoch 26 iteration 24000  Train Error 0.650741 time 0.001002 secs\n",
      "------ Test Error 0.744901\n",
      "epoch 27 iteration 24500  Train Error 0.651142 time 0.001003 secs\n",
      "epoch 27 iteration 25000  Train Error 0.649893 time 0.001002 secs\n",
      "------ Test Error 0.744907\n",
      "epoch 28 iteration 25500  Train Error 0.649782 time 0.001002 secs\n",
      "epoch 28 iteration 26000  Train Error 0.649161 time 0.001003 secs\n",
      "------ Test Error 0.744995\n",
      "epoch 29 iteration 26500  Train Error 0.649061 time 0.001003 secs\n",
      "epoch 29 iteration 27000  Train Error 0.649063 time 0.001003 secs\n",
      "------ Test Error 0.744940\n",
      "epoch 30 iteration 27500  Train Error 0.649459 time 0.000999 secs\n",
      "epoch 31 iteration 28000  Train Error 0.648615 time 0.001003 secs\n",
      "------ Test Error 0.744851\n",
      "epoch 31 iteration 28500  Train Error 0.647684 time 0.001003 secs\n",
      "epoch 32 iteration 29000  Train Error 0.648226 time 0.001001 secs\n",
      "------ Test Error 0.744771\n",
      "epoch 32 iteration 29500  Train Error 0.647075 time 0.001003 secs\n",
      "epoch 33 iteration 30000  Train Error 0.647066 time 0.001003 secs\n",
      "------ Test Error 0.744971\n",
      "epoch 33 iteration 30500  Train Error 0.646547 time 0.001010 secs\n",
      "epoch 34 iteration 31000  Train Error 0.646518 time 0.001003 secs\n",
      "------ Test Error 0.744948\n",
      "epoch 34 iteration 31500  Train Error 0.646590 time 0.001003 secs\n",
      "epoch 35 iteration 32000  Train Error 0.647076 time 0.001003 secs\n",
      "------ Test Error 0.744925\n",
      "epoch 36 iteration 32500  Train Error 0.646332 time 0.001003 secs\n",
      "epoch 36 iteration 33000  Train Error 0.645426 time 0.001003 secs\n",
      "------ Test Error 0.745022\n",
      "epoch 37 iteration 33500  Train Error 0.646060 time 0.001003 secs\n",
      "epoch 37 iteration 34000  Train Error 0.644970 time 0.001506 secs\n",
      "------ Test Error 0.745090\n",
      "epoch 38 iteration 34500  Train Error 0.645026 time 0.001003 secs\n",
      "epoch 38 iteration 35000  Train Error 0.644576 time 0.001002 secs\n",
      "------ Test Error 0.745225\n",
      "epoch 39 iteration 35500  Train Error 0.644590 time 0.001003 secs\n",
      "epoch 39 iteration 36000  Train Error 0.644705 time 0.001002 secs\n",
      "------ Test Error 0.745237\n",
      "epoch 40 iteration 36500  Train Error 0.645251 time 0.001002 secs\n",
      "epoch 41 iteration 37000  Train Error 0.644577 time 0.001003 secs\n",
      "------ Test Error 0.745188\n",
      "epoch 41 iteration 37500  Train Error 0.643681 time 0.001003 secs\n",
      "epoch 42 iteration 38000  Train Error 0.644379 time 0.000000 secs\n",
      "------ Test Error 0.745174\n",
      "epoch 42 iteration 38500  Train Error 0.643330 time 0.001003 secs\n",
      "epoch 43 iteration 39000  Train Error 0.643429 time 0.001003 secs\n",
      "------ Test Error 0.745377\n",
      "epoch 43 iteration 39500  Train Error 0.643029 time 0.001003 secs\n",
      "epoch 44 iteration 40000  Train Error 0.643072 time 0.001002 secs\n",
      "------ Test Error 0.745390\n",
      "epoch 44 iteration 40500  Train Error 0.643213 time 0.001003 secs\n",
      "epoch 45 iteration 41000  Train Error 0.643802 time 0.001003 secs\n",
      "------ Test Error 0.745400\n",
      "epoch 46 iteration 41500  Train Error 0.643182 time 0.001002 secs\n",
      "epoch 46 iteration 42000  Train Error 0.642286 time 0.001016 secs\n",
      "------ Test Error 0.745512\n",
      "epoch 47 iteration 42500  Train Error 0.643033 time 0.001002 secs\n",
      "epoch 47 iteration 43000  Train Error 0.642013 time 0.000998 secs\n",
      "------ Test Error 0.745585\n",
      "epoch 48 iteration 43500  Train Error 0.642142 time 0.001001 secs\n",
      "epoch 48 iteration 44000  Train Error 0.641778 time 0.001004 secs\n",
      "------ Test Error 0.745723\n",
      "epoch 49 iteration 44500  Train Error 0.641841 time 0.001002 secs\n",
      "epoch 49 iteration 45000  Train Error 0.642000 time 0.001002 secs\n",
      "------ Test Error 0.745752\n",
      "------Final Test Error 0.745752\n"
     ]
    }
   ],
   "source": [
    "save_every_n = 500 # save every N iteration\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver = tf.train.Saver(max_to_keep = 100)\n",
    "    counter = 0\n",
    "    errors = deque(maxlen=batch_size)\n",
    "    for e in range(n_epochs):\n",
    "        for x, y, z in get_batch(data_train, batch_size):\n",
    "            \n",
    "            counter +=1\n",
    "            start = time.time()\n",
    "            feed = {user_batch:x, movie_batch:y, rate_batch:z}\n",
    "            pred_batch, _ = sess.run([infer, train_op], feed_dict = feed)\n",
    "            \n",
    "            pred_batch = clip(pred_batch)\n",
    "            errors.append(np.power(pred_batch - np.array(z), 2))\n",
    "            if counter%500==0:\n",
    "                end=time.time()\n",
    "                print('epoch %d iteration %d  Train Error %f time %f secs'%(e,counter,np.mean(errors),end-start))\n",
    "            # check the test set accuracy    \n",
    "            if counter%1000==0:\n",
    "                feed = {user_batch:(np.array(data_test.UserIDs)-1), \n",
    "                        movie_batch:(np.array(data_test.MovieIDs)-1), rate_batch:np.array(data_test.Ratings)}\n",
    "                pred_batch = sess.run([infer], feed_dict = feed)\n",
    "                pred_batch = clip(pred_batch)\n",
    "                test_error = np.mean(np.power(pred_batch-np.array(data_test.Ratings),2))\n",
    "                print('------ Test Error %f'%(test_error))\n",
    "            if counter%save_every_n==0:\n",
    "                saver.save(sess,\"checkpoints/sentiment.ckpt\")   \n",
    "        # find final error\n",
    "    feed = {user_batch:(np.array(data_test.UserIDs)-1), \n",
    "            movie_batch:(np.array(data_test.MovieIDs)-1), rate_batch:np.array(data_test.Ratings)}\n",
    "    pred_batch = sess.run([infer], feed_dict = feed)\n",
    "    pred_batch = clip(pred_batch)\n",
    "    test_error = np.mean(np.power(pred_batch-np.array(data_test.Ratings),2))\n",
    "    print('------Final Test Error %f'%(test_error))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\sentiment.ckpt\n",
      "predicted = 2.720909, real = 3.000000\n"
     ]
    }
   ],
   "source": [
    "# use Model for prediciton\n",
    "un = 45 # number of user from the test set\n",
    "with tf.Session (graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    feed = {user_batch:(np.array(data_test.UserIDs)[un].reshape(-1,)-1), \n",
    "            movie_batch:(np.array(data_test.MovieIDs)[un].reshape(-1,)-1)}\n",
    "    pred_batch = sess.run([infer], feed_dict = feed)\n",
    "    pred_batch = clip(pred_batch)\n",
    "    real = np.array(data_test.Ratings)[un]\n",
    "    print(\"predicted = %f, real = %f\"%(pred_batch,real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2219], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_test.UserIDs)[1].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2764, 2219, 3538, ..., 1145, 1181, 3272], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_test.UserIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2764"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_test.UserIDs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2763], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_test.UserIDs)[0].reshape(-1)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
